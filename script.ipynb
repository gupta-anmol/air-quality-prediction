{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RKP = \"DL031\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\confusement\\miniconda3\\envs\\mlc\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3263: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['StationId', 'Datetime', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3',\n",
      "       'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load datasets and rename columns, load all aqi data but specify metro data name\n",
    "def loadcsv(city=\"./data/rkpuram.csv\"):\n",
    "    met = pd.read_csv(city,delimiter=';',skiprows=24)\n",
    "    aqi = pd.read_csv('./data/station_hour.csv')\n",
    "    print(aqi.columns)\n",
    "    met.rename(columns={'# Date': 'Date',}, inplace=True)\n",
    "    met.rename(columns={'UT time': 'Time',}, inplace=True)\n",
    "    aqi['Time'] = aqi['Datetime'].str[-8:-3]\n",
    "    aqi['Date'] = aqi['Datetime'].str[0:10]\n",
    "    stations = [\"DL\"+str(x).zfill(3) for x in range(1,39)]\n",
    "    split_aqi = {}\n",
    "    for i in range(len(stations)):\n",
    "        split_aqi[stations[i]] = (aqi[aqi['StationId'] == stations[i]])\n",
    "    return met,aqi,split_aqi\n",
    "met,aqi,split_aqi = loadcsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset Size 44035\n",
      "Size before roll 44035\n",
      "Size after roll 12790\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>AQI</th>\n",
       "      <th>...</th>\n",
       "      <th>isWeekend_t-19</th>\n",
       "      <th>isWeekend_t+19</th>\n",
       "      <th>isWeekend_t-20</th>\n",
       "      <th>isWeekend_t+20</th>\n",
       "      <th>isWeekend_t-21</th>\n",
       "      <th>isWeekend_t+21</th>\n",
       "      <th>isWeekend_t-22</th>\n",
       "      <th>isWeekend_t+22</th>\n",
       "      <th>isWeekend_t-23</th>\n",
       "      <th>isWeekend_t+23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>33.00</td>\n",
       "      <td>102.17</td>\n",
       "      <td>6.33</td>\n",
       "      <td>14.45</td>\n",
       "      <td>22.22</td>\n",
       "      <td>23.65</td>\n",
       "      <td>0.17</td>\n",
       "      <td>10.27</td>\n",
       "      <td>18.08</td>\n",
       "      <td>429.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>95.17</td>\n",
       "      <td>184.83</td>\n",
       "      <td>6.72</td>\n",
       "      <td>15.63</td>\n",
       "      <td>23.86</td>\n",
       "      <td>22.06</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11.97</td>\n",
       "      <td>18.58</td>\n",
       "      <td>429.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>77.50</td>\n",
       "      <td>164.67</td>\n",
       "      <td>8.15</td>\n",
       "      <td>32.28</td>\n",
       "      <td>41.18</td>\n",
       "      <td>26.91</td>\n",
       "      <td>8.00</td>\n",
       "      <td>17.28</td>\n",
       "      <td>20.33</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>65.50</td>\n",
       "      <td>154.33</td>\n",
       "      <td>7.64</td>\n",
       "      <td>90.45</td>\n",
       "      <td>94.00</td>\n",
       "      <td>30.74</td>\n",
       "      <td>17.00</td>\n",
       "      <td>18.81</td>\n",
       "      <td>29.83</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>60.50</td>\n",
       "      <td>310.17</td>\n",
       "      <td>14.19</td>\n",
       "      <td>116.38</td>\n",
       "      <td>121.56</td>\n",
       "      <td>28.73</td>\n",
       "      <td>15.00</td>\n",
       "      <td>15.16</td>\n",
       "      <td>33.33</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43839</th>\n",
       "      <td>18.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>20.73</td>\n",
       "      <td>13.30</td>\n",
       "      <td>22.40</td>\n",
       "      <td>0.83</td>\n",
       "      <td>15.35</td>\n",
       "      <td>13.27</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43840</th>\n",
       "      <td>14.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>41.08</td>\n",
       "      <td>23.93</td>\n",
       "      <td>16.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>12.18</td>\n",
       "      <td>15.43</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43841</th>\n",
       "      <td>16.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>2.85</td>\n",
       "      <td>18.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>25.40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>12.35</td>\n",
       "      <td>17.43</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43842</th>\n",
       "      <td>9.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>17.65</td>\n",
       "      <td>10.30</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>10.35</td>\n",
       "      <td>13.00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43843</th>\n",
       "      <td>13.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>17.75</td>\n",
       "      <td>10.85</td>\n",
       "      <td>39.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.70</td>\n",
       "      <td>18.52</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12790 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PM2.5    PM10     NO     NO2     NOx    NH3     CO    SO2     O3  \\\n",
       "165    33.00  102.17   6.33   14.45   22.22  23.65   0.17  10.27  18.08   \n",
       "166    95.17  184.83   6.72   15.63   23.86  22.06  20.00  11.97  18.58   \n",
       "167    77.50  164.67   8.15   32.28   41.18  26.91   8.00  17.28  20.33   \n",
       "168    65.50  154.33   7.64   90.45   94.00  30.74  17.00  18.81  29.83   \n",
       "170    60.50  310.17  14.19  116.38  121.56  28.73  15.00  15.16  33.33   \n",
       "...      ...     ...    ...     ...     ...    ...    ...    ...    ...   \n",
       "43839  18.00   53.00   2.80   20.73   13.30  22.40   0.83  15.35  13.27   \n",
       "43840  14.00   48.00   2.55   41.08   23.93  16.75   0.72  12.18  15.43   \n",
       "43841  16.00   46.00   2.85   18.00   11.90  25.40   0.62  12.35  17.43   \n",
       "43842   9.00   45.00   1.10   17.65   10.30  36.00   0.70  10.35  13.00   \n",
       "43843  13.00   48.00   1.73   17.75   10.85  39.80   0.60   9.70  18.52   \n",
       "\n",
       "         AQI  ...  isWeekend_t-19  isWeekend_t+19  isWeekend_t-20  \\\n",
       "165    429.0  ...             0.0             1.0             0.0   \n",
       "166    429.0  ...             0.0             1.0             0.0   \n",
       "167    318.0  ...             0.0             1.0             0.0   \n",
       "168    318.0  ...             0.0             1.0             0.0   \n",
       "170    318.0  ...             1.0             1.0             0.0   \n",
       "...      ...  ...             ...             ...             ...   \n",
       "43839   79.0  ...             1.0             0.0             1.0   \n",
       "43840   77.0  ...             1.0             0.0             1.0   \n",
       "43841   72.0  ...             1.0             0.0             1.0   \n",
       "43842   69.0  ...             1.0             0.0             1.0   \n",
       "43843   68.0  ...             1.0             0.0             1.0   \n",
       "\n",
       "       isWeekend_t+20  isWeekend_t-21  isWeekend_t+21  isWeekend_t-22  \\\n",
       "165               1.0             0.0             1.0             0.0   \n",
       "166               1.0             0.0             1.0             0.0   \n",
       "167               1.0             0.0             1.0             0.0   \n",
       "168               1.0             0.0             1.0             0.0   \n",
       "170               0.0             0.0             0.0             0.0   \n",
       "...               ...             ...             ...             ...   \n",
       "43839             0.0             1.0             0.0             1.0   \n",
       "43840             0.0             1.0             0.0             1.0   \n",
       "43841             0.0             1.0             0.0             1.0   \n",
       "43842             0.0             1.0             0.0             1.0   \n",
       "43843             0.0             1.0             0.0             1.0   \n",
       "\n",
       "       isWeekend_t+22 isWeekend_t-23  isWeekend_t+23  \n",
       "165               1.0            0.0             1.0  \n",
       "166               1.0            0.0             1.0  \n",
       "167               1.0            0.0             0.0  \n",
       "168               0.0            0.0             0.0  \n",
       "170               0.0            0.0             0.0  \n",
       "...               ...            ...             ...  \n",
       "43839             0.0            1.0             0.0  \n",
       "43840             0.0            1.0             0.0  \n",
       "43841             0.0            1.0             0.0  \n",
       "43842             0.0            1.0             0.0  \n",
       "43843             0.0            1.0             0.0  \n",
       "\n",
       "[12790 rows x 977 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre - processing and loading data\n",
    "class dataset:\n",
    "    def __init__(self,met,aqi,split_aqi):\n",
    "            self.metro_data = met\n",
    "            self.aqi_data = aqi\n",
    "            self.split_aqi = split_aqi\n",
    "    def mergedData(self,station,rlist=['PM2.5','PM10','NO','NO2','NOx','NH3','CO','SO2','O3'],roll=48,shift=168):\n",
    "        df_aqi = self.getdf(station)\n",
    "        df = pd.merge(df_aqi, self.metro_data, how='inner', on=['Date', 'Time'])\n",
    "        print(\"Merged Dataset Size\",len(df))\n",
    "        \n",
    "        #Pre Processing merged Data\n",
    "        df['Year'] = df['Date'].str[0:4]\n",
    "        df['Month'] = df['Date'].str[5:7].astype(np.float64)\n",
    "        df['Day'] = df['Date'].str[8:10].astype(np.float64)\n",
    "        df['Hour'] = df['Time'].str[0:2]\n",
    "        \n",
    "        # TRIG TRANSFORMATIONS\n",
    "        df['windX'] = np.cos(np.deg2rad(df['Wind direction'])) * df['Wind speed']\n",
    "        df['windY'] = np.sin(np.deg2rad(df['Wind direction'])) * df['Wind speed']\n",
    "        df['hourX'] = np.cos((df['Hour'].astype(np.float64)-1)*np.pi/24)\n",
    "        df['hourY'] = np.sin((df['Hour'].astype(np.float64)-1)*np.pi/24)\n",
    "        df['MonthX'] = np.cos((df['Month'].astype(np.float64)-1)*np.pi/12)\n",
    "        df['MonthY'] = np.sin((df['Month'].astype(np.float64)-1)*np.pi/12)\n",
    "        \n",
    "        import datetime\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df['isWeekend'] =  (df['Date'].dt.dayofweek>=5).astype(int)\n",
    "        \n",
    "        df.interpolate(method='linear', limit=5,inplace=True)\n",
    "        \n",
    "        # Drop Additional columns\n",
    "        df.drop('Benzene', axis=1, inplace=True)\n",
    "        df.drop('Toluene',axis=1, inplace=True)\n",
    "        df.drop('Xylene', axis=1,inplace=True)\n",
    "        df.drop('AQI_Bucket',axis=1,inplace=True)\n",
    "        df.drop('Datetime',axis=1,inplace=True)\n",
    "        df.drop('StationId',axis=1,inplace=True)\n",
    "        df.drop('Short-wave irradiation',axis=1,inplace=True)\n",
    "        df.drop('Date',axis=1,inplace=True)\n",
    "        df.drop('Time',axis=1,inplace=True)\n",
    "        \n",
    "        # Rolling and shifting \n",
    "        print(\"Size before roll\",len(df))\n",
    "        for i in rlist:\n",
    "            df[i+'_lag1'] = df[i].shift(24)\n",
    "            df[i+'_lag2'] = df[i].shift(48)\n",
    "        for i in rlist:\n",
    "            df[i+\"_pred1\"] = df[i].shift(-24)\n",
    "            df[i+\"_pred2\"] = df[i].shift(-48)\n",
    "        newlist = rlist + ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "        for i in newlist:\n",
    "            for j in range(24):\n",
    "                df[i+\"_t-\"+str(j)] = df[i].shift(j)\n",
    "                df[i+\"_t+\"+str(j)] = df[i].shift(-j-shift)\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"Size after roll\",len(df))\n",
    "        \n",
    "        return df.copy()\n",
    "    def getdf(self,station):\n",
    "        return self.split_aqi[station]\n",
    "    def plot(self,station):\n",
    "        df = self.getdf(station)\n",
    "    def stats(self):\n",
    "        pass\n",
    "dat = dataset(met,aqi,split_aqi)\n",
    "df = dat.mergedData('DL031')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[33.0, 17.5, 34.5, ..., 29.0, 34.2, 52.5],\n",
       "        [102.17, 43.33, 90.83, ..., 89.83, 111.67, 223.67],\n",
       "        [6.33, 6.57, 6.04, ..., 8.3, 7.07, 6.53],\n",
       "        ...,\n",
       "        [-0.25881904510252063, -0.1305261922200516,\n",
       "         6.123233995736766e-17, ..., -0.4999999999999998,\n",
       "         -0.3826834323650895, -0.25881904510252063],\n",
       "        [0.9659258262890683, 0.9914448613738104, 1.0, ...,\n",
       "         0.8660254037844387, 0.9238795325112868, 0.9659258262890683],\n",
       "        [1, 1.0, 1.0, ..., 0.0, 0.0, 0.0]],\n",
       "\n",
       "       [[95.17, 33.0, 17.5, ..., 42.67, 29.0, 34.2],\n",
       "        [184.83, 102.17, 43.33, ..., 111.5, 89.83, 111.67],\n",
       "        [6.72, 6.33, 6.57, ..., 7.13, 8.3, 7.07],\n",
       "        ...,\n",
       "        [-0.3826834323650895, -0.25881904510252063, -0.1305261922200516,\n",
       "         ..., -0.6087614290087207, -0.4999999999999998,\n",
       "         -0.3826834323650895],\n",
       "        [0.9238795325112868, 0.9659258262890683, 0.9914448613738104,\n",
       "         ..., 0.7933533402912352, 0.8660254037844387,\n",
       "         0.9238795325112868],\n",
       "        [1, 1.0, 1.0, ..., 0.0, 0.0, 0.0]],\n",
       "\n",
       "       [[77.5, 95.17, 33.0, ..., 61.67, 42.67, 29.0],\n",
       "        [164.67, 184.83, 102.17, ..., 120.67, 111.5, 89.83],\n",
       "        [8.15, 6.72, 6.33, ..., 7.98, 7.13, 8.3],\n",
       "        ...,\n",
       "        [-0.4999999999999998, -0.3826834323650895, -0.25881904510252063,\n",
       "         ..., -0.7071067811865475, -0.6087614290087207,\n",
       "         -0.4999999999999998],\n",
       "        [0.8660254037844387, 0.9238795325112868, 0.9659258262890683,\n",
       "         ..., 0.7071067811865476, 0.7933533402912352,\n",
       "         0.8660254037844387],\n",
       "        [1, 1.0, 1.0, ..., 0.0, 0.0, 0.0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[16.0, 14.0, 18.0, ..., 22.0, 22.0, 25.0],\n",
       "        [46.0, 48.0, 53.0, ..., 83.0, 106.0, 183.0],\n",
       "        [2.85, 2.55, 2.8, ..., 1.75, 2.2, 2.83],\n",
       "        ...,\n",
       "        [-0.1305261922200516, 6.123233995736766e-17, 0.1305261922200517,\n",
       "         ..., -0.3826834323650895, -0.25881904510252063,\n",
       "         -0.1305261922200516],\n",
       "        [0.9914448613738104, 1.0, 0.9914448613738104, ...,\n",
       "         0.9238795325112868, 0.9659258262890683, 0.9914448613738104],\n",
       "        [0, 0.0, 0.0, ..., 1.0, 1.0, 1.0]],\n",
       "\n",
       "       [[9.0, 16.0, 14.0, ..., 22.0, 22.0, 22.0],\n",
       "        [45.0, 46.0, 48.0, ..., 85.0, 83.0, 106.0],\n",
       "        [1.1, 2.85, 2.55, ..., 1.62, 1.75, 2.2],\n",
       "        ...,\n",
       "        [-0.25881904510252063, -0.1305261922200516,\n",
       "         6.123233995736766e-17, ..., -0.4999999999999998,\n",
       "         -0.3826834323650895, -0.25881904510252063],\n",
       "        [0.9659258262890683, 0.9914448613738104, 1.0, ...,\n",
       "         0.8660254037844387, 0.9238795325112868, 0.9659258262890683],\n",
       "        [0, 0.0, 0.0, ..., 1.0, 1.0, 1.0]],\n",
       "\n",
       "       [[13.0, 9.0, 16.0, ..., 22.0, 22.0, 22.0],\n",
       "        [48.0, 45.0, 46.0, ..., 86.0, 85.0, 83.0],\n",
       "        [1.73, 1.1, 2.85, ..., 1.77, 1.62, 1.75],\n",
       "        ...,\n",
       "        [-0.3826834323650895, -0.25881904510252063, -0.1305261922200516,\n",
       "         ..., -0.6087614290087207, -0.4999999999999998,\n",
       "         -0.3826834323650895],\n",
       "        [0.9238795325112868, 0.9659258262890683, 0.9914448613738104,\n",
       "         ..., 0.7933533402912352, 0.8660254037844387,\n",
       "         0.9238795325112868],\n",
       "        [0, 0.0, 0.0, ..., 1.0, 1.0, 1.0]]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN Model Testing as well\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "features = []\n",
    "rlist=['PM2.5','PM10','NO','NO2','CO']\n",
    "newlist = rlist + ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "print(len(newlist))\n",
    "for i in newlist:\n",
    "    for j in range(24):\n",
    "        features.append(i+'_t-'+str(j))\n",
    "predVector = []\n",
    "for j in range(24):\n",
    "    predVector.append('PM2.5_t+'+str(j))\n",
    "X = df[features]\n",
    "y = df[predVector]\n",
    "X.shape\n",
    "np.array(X).reshape(12790,15,24)\n",
    "scaler = StandardScaler()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "scaler.fit(Xtrain)\n",
    "print(Xtrain.shape)\n",
    "with tf.device('/CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=360, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(24, activation='linear'))\n",
    "    model.summary()\n",
    "    #Fit\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "    history = model.fit(scaler.transform(Xtrain), ytrain, epochs=100, batch_size=50,  verbose=1, validation_split=0.2)\n",
    "    #Print Accuracy\n",
    "    testPred = model.predict(scaler.transform(Xtest))\n",
    "    trainPred = model.predict(scaler.transform(Xtrain))\n",
    "    print(mean_squared_error(testPred, ytest,squared=False))\n",
    "    print(mean_squared_error(trainPred, ytrain,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5695458844542312\n",
      "54.50302447946837\n",
      "55.00987602265274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression , mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "dfTrain = df[:]\n",
    "features = ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "features.append(\"PM2.5_lag1\")\n",
    "features.append(\"PM2.5_lag2\")\n",
    "\n",
    "features.append(\"PM10_lag1\")\n",
    "features.append(\"PM10_lag2\")\n",
    "\n",
    "features.append(\"NO2_lag1\")\n",
    "features.append(\"NO2_lag2\")\n",
    "\n",
    "features.append(\"SO2_lag1\")\n",
    "features.append(\"SO2_lag2\")\n",
    "\n",
    "features.append(\"NO_lag1\")\n",
    "features.append(\"NO_lag2\")\n",
    "\n",
    "features.append(\"NOx_lag1\")\n",
    "features.append(\"NOx_lag2\")\n",
    "\n",
    "features.append(\"CO_lag1\")\n",
    "features.append(\"CO_lag2\")\n",
    "\n",
    "features.append(\"O3_lag1\")\n",
    "features.append(\"O3_lag2\")\n",
    "\n",
    "features.append(\"NH3_lag1\")\n",
    "features.append(\"NH3_lag2\")\n",
    "\n",
    "features = []\n",
    "rlist=['PM2.5','PM10','NO','NO2','CO']\n",
    "newlist = rlist + ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "for i in newlist:\n",
    "    for j in range(24):\n",
    "        features.append(i+'_t-'+str(j))\n",
    "\n",
    "X = df[features]\n",
    "y = df['PM2.5_pred1']\n",
    "scaler = StandardScaler()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "scaler.fit(Xtrain)\n",
    "\n",
    "reg = LinearRegression().fit(scaler.transform(Xtrain), ytrain)\n",
    "\n",
    "testPred = reg.predict(scaler.transform(Xtest))\n",
    "trainPred = reg.predict(scaler.transform(Xtrain))\n",
    "mse = np.mean((testPred - np.array(ytest))*(testPred - np.array(ytest)))\n",
    "print(reg.score(scaler.transform(Xtest), ytest))\n",
    "print(mean_squared_error(testPred, ytest,squared=False))\n",
    "print(mean_squared_error(trainPred, ytrain,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\confusement\\miniconda3\\envs\\mlc\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685427631493239\n",
      "46.59265479233718\n",
      "42.94414431488849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression , mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "dfTrain = df[:]\n",
    "features = ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "features.append(\"PM2.5_lag1\")\n",
    "features.append(\"PM2.5_lag2\")\n",
    "\n",
    "features.append(\"PM10_lag1\")\n",
    "features.append(\"PM10_lag2\")\n",
    "\n",
    "features.append(\"NO2_lag1\")\n",
    "features.append(\"NO2_lag2\")\n",
    "\n",
    "features.append(\"SO2_lag1\")\n",
    "features.append(\"SO2_lag2\")\n",
    "\n",
    "features.append(\"NO_lag1\")\n",
    "features.append(\"NO_lag2\")\n",
    "\n",
    "features.append(\"NOx_lag1\")\n",
    "features.append(\"NOx_lag2\")\n",
    "\n",
    "features.append(\"CO_lag1\")\n",
    "features.append(\"CO_lag2\")\n",
    "\n",
    "features.append(\"O3_lag1\")\n",
    "features.append(\"O3_lag2\")\n",
    "\n",
    "features.append(\"NH3_lag1\")\n",
    "features.append(\"NH3_lag2\")\n",
    "\n",
    "features = []\n",
    "rlist=['PM2.5','PM10','NO','NO2','CO']\n",
    "newlist = rlist + ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "for i in newlist:\n",
    "    for j in range(24):\n",
    "        features.append(i+'_t-'+str(j))\n",
    "        \n",
    "X = df[features]\n",
    "y = df['PM2.5_pred1']\n",
    "scaler = StandardScaler()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "scaler.fit(Xtrain)\n",
    "\n",
    "reg = MLPRegressor(random_state=1, max_iter=100).fit(scaler.transform(Xtrain), ytrain)\n",
    "\n",
    "testPred = reg.predict(scaler.transform(Xtest))\n",
    "trainPred = reg.predict(scaler.transform(Xtrain))\n",
    "mse = np.mean((testPred - np.array(ytest))*(testPred - np.array(ytest)))\n",
    "print(reg.score(scaler.transform(Xtest), ytest))\n",
    "print(mean_squared_error(testPred, ytest,squared=False))\n",
    "print(mean_squared_error(trainPred, ytrain,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44686265572761963\n",
      "61.78366409828595\n",
      "63.108555288839455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression , mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "dfTrain = df[:]\n",
    "features = ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "features.append(\"PM2.5_lag1\")\n",
    "features.append(\"PM2.5_lag2\")\n",
    "\n",
    "features.append(\"PM10_lag1\")\n",
    "features.append(\"PM10_lag2\")\n",
    "\n",
    "features.append(\"NO2_lag1\")\n",
    "features.append(\"NO2_lag2\")\n",
    "\n",
    "features.append(\"SO2_lag1\")\n",
    "features.append(\"SO2_lag2\")\n",
    "\n",
    "features.append(\"NO_lag1\")\n",
    "features.append(\"NO_lag2\")\n",
    "\n",
    "features.append(\"NOx_lag1\")\n",
    "features.append(\"NOx_lag2\")\n",
    "\n",
    "features.append(\"CO_lag1\")\n",
    "features.append(\"CO_lag2\")\n",
    "\n",
    "features.append(\"O3_lag1\")\n",
    "features.append(\"O3_lag2\")\n",
    "\n",
    "features.append(\"NH3_lag1\")\n",
    "features.append(\"NH3_lag2\")\n",
    "\n",
    "# features = []\n",
    "# rlist=['PM2.5','PM10','NO','NO2','CO']\n",
    "# newlist = rlist + ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "# for i in newlist:\n",
    "#     for j in range(24):\n",
    "#         features.append(i+'_t-'+str(j))\n",
    "\n",
    "X = df[features]\n",
    "y = df['PM2.5_pred1']\n",
    "scaler = StandardScaler()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "scaler.fit(Xtrain)\n",
    "\n",
    "reg = SVR(C=1.0, epsilon=0.2).fit(scaler.transform(Xtrain), ytrain)\n",
    "\n",
    "testPred = reg.predict(scaler.transform(Xtest))\n",
    "trainPred = reg.predict(scaler.transform(Xtrain))\n",
    "mse = np.mean((testPred - np.array(ytest))*(testPred - np.array(ytest)))\n",
    "print(reg.score(scaler.transform(Xtest), ytest))\n",
    "print(mean_squared_error(testPred, ytest,squared=False))\n",
    "print(mean_squared_error(trainPred, ytrain,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8569, 360)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 200)               72200     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 24)                2424      \n",
      "=================================================================\n",
      "Total params: 104,824\n",
      "Trainable params: 104,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6855 samples, validate on 1714 samples\n",
      "Epoch 1/100\n",
      "6855/6855 [==============================] - 1s 115us/step - loss: 8309.0508 - mse: 8309.0508 - mae: 63.0670 - val_loss: 4379.9809 - val_mse: 4379.9805 - val_mae: 46.6007\n",
      "Epoch 2/100\n",
      "6855/6855 [==============================] - 1s 109us/step - loss: 4454.1584 - mse: 4454.1582 - mae: 46.6320 - val_loss: 4305.2399 - val_mse: 4305.2397 - val_mae: 47.5071\n",
      "Epoch 3/100\n",
      "6855/6855 [==============================] - 1s 115us/step - loss: 4318.2445 - mse: 4318.2451 - mae: 46.0333 - val_loss: 4119.4418 - val_mse: 4119.4419 - val_mae: 45.3639\n",
      "Epoch 4/100\n",
      "6855/6855 [==============================] - 1s 94us/step - loss: 4153.5816 - mse: 4153.5820 - mae: 45.0256 - val_loss: 3946.3698 - val_mse: 3946.3696 - val_mae: 44.3598\n",
      "Epoch 5/100\n",
      "6855/6855 [==============================] - 1s 105us/step - loss: 3930.0813 - mse: 3930.0813 - mae: 43.5269 - val_loss: 3800.8963 - val_mse: 3800.8965 - val_mae: 42.5525\n",
      "Epoch 6/100\n",
      "6855/6855 [==============================] - 1s 112us/step - loss: 3767.2328 - mse: 3767.2327 - mae: 42.4204 - val_loss: 3600.5627 - val_mse: 3600.5625 - val_mae: 41.8675\n",
      "Epoch 7/100\n",
      "6855/6855 [==============================] - 1s 117us/step - loss: 3626.2942 - mse: 3626.2947 - mae: 41.4814 - val_loss: 3490.6497 - val_mse: 3490.6497 - val_mae: 41.1371\n",
      "Epoch 8/100\n",
      "6855/6855 [==============================] - 1s 122us/step - loss: 3486.1876 - mse: 3486.1870 - mae: 40.5335 - val_loss: 3364.0821 - val_mse: 3364.0820 - val_mae: 40.0079\n",
      "Epoch 9/100\n",
      "6855/6855 [==============================] - 1s 143us/step - loss: 3340.8611 - mse: 3340.8601 - mae: 39.5399 - val_loss: 3233.0603 - val_mse: 3233.0613 - val_mae: 38.7013\n",
      "Epoch 10/100\n",
      "6855/6855 [==============================] - 1s 106us/step - loss: 3209.9103 - mse: 3209.9104 - mae: 38.5882 - val_loss: 3091.9288 - val_mse: 3091.9287 - val_mae: 38.4238\n",
      "Epoch 11/100\n",
      "6855/6855 [==============================] - 1s 107us/step - loss: 3038.8932 - mse: 3038.8933 - mae: 37.5948 - val_loss: 2971.0954 - val_mse: 2971.0955 - val_mae: 37.3810\n",
      "Epoch 12/100\n",
      "6855/6855 [==============================] - 1s 93us/step - loss: 2902.5776 - mse: 2902.5769 - mae: 36.7366 - val_loss: 2870.0884 - val_mse: 2870.0884 - val_mae: 37.6606\n",
      "Epoch 13/100\n",
      "6855/6855 [==============================] - 1s 95us/step - loss: 2745.2341 - mse: 2745.2341 - mae: 35.5544 - val_loss: 2741.9229 - val_mse: 2741.9231 - val_mae: 36.1995\n",
      "Epoch 14/100\n",
      "6855/6855 [==============================] - 1s 110us/step - loss: 2640.3511 - mse: 2640.3511 - mae: 34.8988 - val_loss: 2648.7487 - val_mse: 2648.7485 - val_mae: 35.4468\n",
      "Epoch 15/100\n",
      "6855/6855 [==============================] - 1s 138us/step - loss: 2523.5544 - mse: 2523.5540 - mae: 34.1082 - val_loss: 2597.8590 - val_mse: 2597.8591 - val_mae: 34.3114\n",
      "Epoch 16/100\n",
      "6855/6855 [==============================] - 1s 117us/step - loss: 2404.3001 - mse: 2404.2998 - mae: 33.2656 - val_loss: 2477.5860 - val_mse: 2477.5859 - val_mae: 34.3386\n",
      "Epoch 17/100\n",
      "6855/6855 [==============================] - 1s 136us/step - loss: 2305.2574 - mse: 2305.2568 - mae: 32.5906 - val_loss: 2427.9242 - val_mse: 2427.9241 - val_mae: 34.0787\n",
      "Epoch 18/100\n",
      "6855/6855 [==============================] - 1s 123us/step - loss: 2208.8648 - mse: 2208.8645 - mae: 31.9471 - val_loss: 2406.6956 - val_mse: 2406.6956 - val_mae: 32.9069\n",
      "Epoch 19/100\n",
      "6855/6855 [==============================] - 1s 118us/step - loss: 2149.9050 - mse: 2149.9053 - mae: 31.5196 - val_loss: 2287.8447 - val_mse: 2287.8447 - val_mae: 33.1951\n",
      "Epoch 20/100\n",
      "6855/6855 [==============================] - 1s 135us/step - loss: 2063.4924 - mse: 2063.4922 - mae: 30.9380 - val_loss: 2248.0697 - val_mse: 2248.0698 - val_mae: 32.8210\n",
      "Epoch 21/100\n",
      "6855/6855 [==============================] - 1s 135us/step - loss: 2009.4672 - mse: 2009.4672 - mae: 30.5610 - val_loss: 2207.1260 - val_mse: 2207.1260 - val_mae: 32.4090\n",
      "Epoch 22/100\n",
      "6855/6855 [==============================] - 1s 95us/step - loss: 1957.1871 - mse: 1957.1877 - mae: 30.1907 - val_loss: 2208.9145 - val_mse: 2208.9143 - val_mae: 32.6886\n",
      "Epoch 23/100\n",
      "6855/6855 [==============================] - 1s 97us/step - loss: 1925.6476 - mse: 1925.6476 - mae: 29.9804 - val_loss: 2198.8875 - val_mse: 2198.8875 - val_mae: 32.8807\n",
      "Epoch 24/100\n",
      "6855/6855 [==============================] - 1s 95us/step - loss: 1881.5686 - mse: 1881.5691 - mae: 29.6607 - val_loss: 2093.4296 - val_mse: 2093.4297 - val_mae: 31.3503\n",
      "Epoch 25/100\n",
      "6855/6855 [==============================] - 1s 98us/step - loss: 1828.5738 - mse: 1828.5735 - mae: 29.2005 - val_loss: 2081.7707 - val_mse: 2081.7708 - val_mae: 31.0342\n",
      "Epoch 26/100\n",
      "6855/6855 [==============================] - 1s 132us/step - loss: 1794.5711 - mse: 1794.5714 - mae: 28.9473 - val_loss: 2055.5629 - val_mse: 2055.5627 - val_mae: 31.1822\n",
      "Epoch 27/100\n",
      "6855/6855 [==============================] - 1s 123us/step - loss: 1763.8551 - mse: 1763.8551 - mae: 28.6967 - val_loss: 2018.2108 - val_mse: 2018.2109 - val_mae: 31.0297\n",
      "Epoch 28/100\n",
      "6855/6855 [==============================] - 1s 116us/step - loss: 1726.9085 - mse: 1726.9082 - mae: 28.3975 - val_loss: 2003.1630 - val_mse: 2003.1632 - val_mae: 30.9712\n",
      "Epoch 29/100\n",
      "6855/6855 [==============================] - 1s 116us/step - loss: 1700.5693 - mse: 1700.5698 - mae: 28.1975 - val_loss: 1984.6721 - val_mse: 1984.6721 - val_mae: 30.6795\n",
      "Epoch 30/100\n",
      "6855/6855 [==============================] - 1s 119us/step - loss: 1676.3033 - mse: 1676.3030 - mae: 28.0141 - val_loss: 1969.0534 - val_mse: 1969.0536 - val_mae: 30.3888\n",
      "Epoch 31/100\n",
      "6855/6855 [==============================] - 1s 138us/step - loss: 1657.0582 - mse: 1657.0583 - mae: 27.8721 - val_loss: 1951.7274 - val_mse: 1951.7274 - val_mae: 30.2785\n",
      "Epoch 32/100\n",
      "6855/6855 [==============================] - 1s 122us/step - loss: 1634.7988 - mse: 1634.7993 - mae: 27.6779 - val_loss: 1950.2315 - val_mse: 1950.2318 - val_mae: 30.5468\n",
      "Epoch 33/100\n",
      "6855/6855 [==============================] - 1s 118us/step - loss: 1614.1869 - mse: 1614.1868 - mae: 27.5304 - val_loss: 1909.0244 - val_mse: 1909.0245 - val_mae: 29.8875\n",
      "Epoch 34/100\n",
      "6855/6855 [==============================] - 1s 98us/step - loss: 1581.4456 - mse: 1581.4453 - mae: 27.2421 - val_loss: 1900.1663 - val_mse: 1900.1663 - val_mae: 29.9104\n",
      "Epoch 35/100\n",
      "6855/6855 [==============================] - 1s 93us/step - loss: 1569.1170 - mse: 1569.1167 - mae: 27.2032 - val_loss: 1868.1356 - val_mse: 1868.1355 - val_mae: 29.9104\n",
      "Epoch 36/100\n",
      "6855/6855 [==============================] - 1s 96us/step - loss: 1543.0560 - mse: 1543.0558 - mae: 26.9525 - val_loss: 1859.7485 - val_mse: 1859.7485 - val_mae: 29.4879\n",
      "Epoch 37/100\n",
      "6855/6855 [==============================] - 1s 96us/step - loss: 1527.4660 - mse: 1527.4661 - mae: 26.8527 - val_loss: 1851.1415 - val_mse: 1851.1414 - val_mae: 29.6165\n",
      "Epoch 38/100\n",
      "6855/6855 [==============================] - 1s 100us/step - loss: 1498.1246 - mse: 1498.1248 - mae: 26.6174 - val_loss: 1834.3296 - val_mse: 1834.3298 - val_mae: 29.4102\n",
      "Epoch 39/100\n",
      "6855/6855 [==============================] - 1s 114us/step - loss: 1485.1427 - mse: 1485.1422 - mae: 26.5166 - val_loss: 1824.0019 - val_mse: 1824.0017 - val_mae: 29.3469\n",
      "Epoch 40/100\n",
      "6855/6855 [==============================] - 1s 108us/step - loss: 1456.5346 - mse: 1456.5343 - mae: 26.2785 - val_loss: 1791.8186 - val_mse: 1791.8186 - val_mae: 29.2485\n",
      "Epoch 41/100\n",
      "6855/6855 [==============================] - 1s 117us/step - loss: 1439.6803 - mse: 1439.6801 - mae: 26.1258 - val_loss: 1794.5306 - val_mse: 1794.5305 - val_mae: 29.4921\n",
      "Epoch 42/100\n",
      "6855/6855 [==============================] - 1s 101us/step - loss: 1414.6445 - mse: 1414.6445 - mae: 25.9260 - val_loss: 1799.3507 - val_mse: 1799.3508 - val_mae: 28.8777\n",
      "Epoch 43/100\n",
      "6855/6855 [==============================] - 1s 104us/step - loss: 1389.9022 - mse: 1389.9027 - mae: 25.7350 - val_loss: 1743.9225 - val_mse: 1743.9222 - val_mae: 28.8176\n",
      "Epoch 44/100\n",
      "6855/6855 [==============================] - 1s 102us/step - loss: 1372.1187 - mse: 1372.1190 - mae: 25.6055 - val_loss: 1740.3871 - val_mse: 1740.3872 - val_mae: 29.1735\n",
      "Epoch 45/100\n",
      "6855/6855 [==============================] - 1s 100us/step - loss: 1362.8167 - mse: 1362.8168 - mae: 25.5521 - val_loss: 1732.9338 - val_mse: 1732.9335 - val_mae: 28.8346\n",
      "Epoch 46/100\n",
      "6855/6855 [==============================] - 1s 100us/step - loss: 1338.9226 - mse: 1338.9222 - mae: 25.3339 - val_loss: 1695.7375 - val_mse: 1695.7375 - val_mae: 28.6601\n",
      "Epoch 47/100\n",
      "6855/6855 [==============================] - 1s 101us/step - loss: 1315.2737 - mse: 1315.2739 - mae: 25.1183 - val_loss: 1678.8224 - val_mse: 1678.8225 - val_mae: 28.2694\n",
      "Epoch 48/100\n",
      "6855/6855 [==============================] - 1s 101us/step - loss: 1300.5171 - mse: 1300.5167 - mae: 25.0144 - val_loss: 1676.1148 - val_mse: 1676.1150 - val_mae: 28.2272\n",
      "Epoch 49/100\n",
      "6855/6855 [==============================] - 1s 101us/step - loss: 1288.5673 - mse: 1288.5676 - mae: 24.9243 - val_loss: 1662.7076 - val_mse: 1662.7075 - val_mae: 28.3276\n",
      "Epoch 50/100\n",
      "6855/6855 [==============================] - 1s 102us/step - loss: 1267.4541 - mse: 1267.4540 - mae: 24.7144 - val_loss: 1653.7069 - val_mse: 1653.7072 - val_mae: 28.1140\n",
      "Epoch 51/100\n",
      "6855/6855 [==============================] - 1s 84us/step - loss: 1246.4424 - mse: 1246.4423 - mae: 24.5098 - val_loss: 1628.1482 - val_mse: 1628.1482 - val_mae: 28.1022\n",
      "Epoch 52/100\n",
      "6855/6855 [==============================] - 1s 82us/step - loss: 1233.0275 - mse: 1233.0276 - mae: 24.3952 - val_loss: 1641.2886 - val_mse: 1641.2885 - val_mae: 28.3091\n",
      "Epoch 53/100\n",
      "6855/6855 [==============================] - 1s 83us/step - loss: 1220.8255 - mse: 1220.8251 - mae: 24.3168 - val_loss: 1627.8296 - val_mse: 1627.8292 - val_mae: 27.7889\n",
      "Epoch 54/100\n",
      "6855/6855 [==============================] - 1s 82us/step - loss: 1201.9873 - mse: 1201.9875 - mae: 24.1516 - val_loss: 1613.0340 - val_mse: 1613.0338 - val_mae: 28.0653\n",
      "Epoch 55/100\n",
      "6855/6855 [==============================] - 1s 82us/step - loss: 1187.1506 - mse: 1187.1506 - mae: 23.9957 - val_loss: 1584.9315 - val_mse: 1584.9318 - val_mae: 27.8132\n",
      "Epoch 56/100\n",
      "6855/6855 [==============================] - 1s 114us/step - loss: 1173.5191 - mse: 1173.5193 - mae: 23.8841 - val_loss: 1580.3582 - val_mse: 1580.3583 - val_mae: 27.4865\n",
      "Epoch 57/100\n",
      "6855/6855 [==============================] - 1s 123us/step - loss: 1164.1502 - mse: 1164.1501 - mae: 23.7745 - val_loss: 1594.9716 - val_mse: 1594.9717 - val_mae: 27.7470\n",
      "Epoch 58/100\n",
      "6855/6855 [==============================] - 1s 129us/step - loss: 1151.3431 - mse: 1151.3431 - mae: 23.6695 - val_loss: 1575.4820 - val_mse: 1575.4821 - val_mae: 27.6078\n",
      "Epoch 59/100\n",
      "6855/6855 [==============================] - 1s 124us/step - loss: 1147.1171 - mse: 1147.1172 - mae: 23.6234 - val_loss: 1558.3035 - val_mse: 1558.3040 - val_mae: 27.4983\n",
      "Epoch 60/100\n",
      "6855/6855 [==============================] - 1s 120us/step - loss: 1130.7698 - mse: 1130.7697 - mae: 23.4707 - val_loss: 1558.4466 - val_mse: 1558.4467 - val_mae: 27.2664\n",
      "Epoch 61/100\n",
      "6855/6855 [==============================] - 1s 116us/step - loss: 1116.8784 - mse: 1116.8784 - mae: 23.3186 - val_loss: 1537.6835 - val_mse: 1537.6832 - val_mae: 27.1918\n",
      "Epoch 62/100\n",
      "6855/6855 [==============================] - 1s 121us/step - loss: 1112.5199 - mse: 1112.5200 - mae: 23.3041 - val_loss: 1529.1122 - val_mse: 1529.1123 - val_mae: 27.0898\n",
      "Epoch 63/100\n",
      "6855/6855 [==============================] - 1s 122us/step - loss: 1094.5038 - mse: 1094.5039 - mae: 23.1165 - val_loss: 1526.3524 - val_mse: 1526.3524 - val_mae: 27.0882\n",
      "Epoch 64/100\n",
      "6855/6855 [==============================] - 1s 114us/step - loss: 1080.3696 - mse: 1080.3696 - mae: 22.9520 - val_loss: 1519.1723 - val_mse: 1519.1726 - val_mae: 27.0114\n",
      "Epoch 65/100\n",
      "6855/6855 [==============================] - 1s 104us/step - loss: 1071.9252 - mse: 1071.9253 - mae: 22.8910 - val_loss: 1509.5296 - val_mse: 1509.5298 - val_mae: 27.1078\n",
      "Epoch 66/100\n",
      "6855/6855 [==============================] - 1s 98us/step - loss: 1069.1808 - mse: 1069.1808 - mae: 22.8558 - val_loss: 1513.8518 - val_mse: 1513.8518 - val_mae: 26.9867\n",
      "Epoch 67/100\n",
      "6855/6855 [==============================] - 1s 97us/step - loss: 1050.6543 - mse: 1050.6541 - mae: 22.6538 - val_loss: 1503.2386 - val_mse: 1503.2385 - val_mae: 27.0949\n",
      "Epoch 68/100\n",
      "6855/6855 [==============================] - 1s 96us/step - loss: 1055.7956 - mse: 1055.7957 - mae: 22.7426 - val_loss: 1495.0159 - val_mse: 1495.0157 - val_mae: 26.8626\n",
      "Epoch 69/100\n",
      "6855/6855 [==============================] - 1s 108us/step - loss: 1033.6629 - mse: 1033.6628 - mae: 22.4809 - val_loss: 1505.9496 - val_mse: 1505.9497 - val_mae: 27.1623\n",
      "Epoch 70/100\n",
      "6855/6855 [==============================] - 1s 118us/step - loss: 1023.4980 - mse: 1023.4981 - mae: 22.3855 - val_loss: 1487.9487 - val_mse: 1487.9486 - val_mae: 26.9748\n",
      "Epoch 71/100\n",
      "6855/6855 [==============================] - 1s 120us/step - loss: 1022.9524 - mse: 1022.9526 - mae: 22.3852 - val_loss: 1499.7203 - val_mse: 1499.7206 - val_mae: 27.1678\n",
      "Epoch 72/100\n",
      "6855/6855 [==============================] - 1s 116us/step - loss: 1012.6753 - mse: 1012.6754 - mae: 22.2792 - val_loss: 1488.2207 - val_mse: 1488.2208 - val_mae: 27.0050\n",
      "Epoch 73/100\n",
      "6855/6855 [==============================] - 1s 131us/step - loss: 998.4750 - mse: 998.4750 - mae: 22.1326 - val_loss: 1478.5356 - val_mse: 1478.5353 - val_mae: 26.6676\n",
      "Epoch 74/100\n",
      "6855/6855 [==============================] - 1s 119us/step - loss: 991.8004 - mse: 991.8005 - mae: 22.0449 - val_loss: 1483.6846 - val_mse: 1483.6848 - val_mae: 26.7164\n",
      "Epoch 75/100\n",
      "6855/6855 [==============================] - 1s 125us/step - loss: 981.1330 - mse: 981.1330 - mae: 21.9399 - val_loss: 1458.9936 - val_mse: 1458.9934 - val_mae: 26.4956\n",
      "Epoch 76/100\n",
      "6855/6855 [==============================] - 1s 125us/step - loss: 970.0355 - mse: 970.0355 - mae: 21.7875 - val_loss: 1466.6880 - val_mse: 1466.6884 - val_mae: 26.7580\n",
      "Epoch 77/100\n",
      "6855/6855 [==============================] - 1s 121us/step - loss: 969.0204 - mse: 969.0201 - mae: 21.8215 - val_loss: 1463.2497 - val_mse: 1463.2495 - val_mae: 26.6329\n",
      "Epoch 78/100\n",
      "6855/6855 [==============================] - 1s 122us/step - loss: 963.3176 - mse: 963.3176 - mae: 21.7358 - val_loss: 1451.9179 - val_mse: 1451.9177 - val_mae: 26.6182\n",
      "Epoch 79/100\n",
      "6855/6855 [==============================] - 1s 123us/step - loss: 956.1658 - mse: 956.1660 - mae: 21.7002 - val_loss: 1464.5119 - val_mse: 1464.5120 - val_mae: 26.6501\n",
      "Epoch 80/100\n",
      "6855/6855 [==============================] - 1s 122us/step - loss: 947.5671 - mse: 947.5670 - mae: 21.5739 - val_loss: 1453.5377 - val_mse: 1453.5380 - val_mae: 26.5088\n",
      "Epoch 81/100\n",
      "6855/6855 [==============================] - 1s 124us/step - loss: 935.2103 - mse: 935.2104 - mae: 21.4422 - val_loss: 1451.4512 - val_mse: 1451.4512 - val_mae: 26.5877\n",
      "Epoch 82/100\n",
      "6855/6855 [==============================] - 1s 118us/step - loss: 926.8044 - mse: 926.8043 - mae: 21.3249 - val_loss: 1448.0511 - val_mse: 1448.0511 - val_mae: 26.4564\n",
      "Epoch 83/100\n",
      "6855/6855 [==============================] - 1s 124us/step - loss: 929.6251 - mse: 929.6250 - mae: 21.3763 - val_loss: 1458.2201 - val_mse: 1458.2202 - val_mae: 26.5950\n",
      "Epoch 84/100\n",
      "6855/6855 [==============================] - 1s 120us/step - loss: 920.2854 - mse: 920.2855 - mae: 21.2848 - val_loss: 1451.9002 - val_mse: 1451.9003 - val_mae: 26.3742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "6855/6855 [==============================] - 1s 113us/step - loss: 919.4138 - mse: 919.4137 - mae: 21.2870 - val_loss: 1454.2937 - val_mse: 1454.2937 - val_mae: 26.6006\n",
      "Epoch 86/100\n",
      "6855/6855 [==============================] - 1s 115us/step - loss: 910.4268 - mse: 910.4268 - mae: 21.1605 - val_loss: 1456.6155 - val_mse: 1456.6154 - val_mae: 26.6129\n",
      "Epoch 87/100\n",
      "6855/6855 [==============================] - 1s 112us/step - loss: 896.8170 - mse: 896.8169 - mae: 20.9925 - val_loss: 1434.1384 - val_mse: 1434.1384 - val_mae: 26.4222\n",
      "Epoch 88/100\n",
      "6855/6855 [==============================] - 1s 107us/step - loss: 889.4265 - mse: 889.4266 - mae: 20.9226 - val_loss: 1429.7807 - val_mse: 1429.7809 - val_mae: 26.2525\n",
      "Epoch 89/100\n",
      "6855/6855 [==============================] - 1s 92us/step - loss: 884.4129 - mse: 884.4128 - mae: 20.8641 - val_loss: 1448.8451 - val_mse: 1448.8450 - val_mae: 26.5517\n",
      "Epoch 90/100\n",
      "6855/6855 [==============================] - 1s 98us/step - loss: 880.1832 - mse: 880.1830 - mae: 20.8124 - val_loss: 1445.7557 - val_mse: 1445.7557 - val_mae: 26.6098\n",
      "Epoch 91/100\n",
      "6855/6855 [==============================] - 1s 95us/step - loss: 877.5480 - mse: 877.5482 - mae: 20.7875 - val_loss: 1435.6000 - val_mse: 1435.5997 - val_mae: 26.4391\n",
      "Epoch 92/100\n",
      "6855/6855 [==============================] - 1s 93us/step - loss: 874.1864 - mse: 874.1865 - mae: 20.7766 - val_loss: 1422.7934 - val_mse: 1422.7935 - val_mae: 26.3164\n",
      "Epoch 93/100\n",
      "6855/6855 [==============================] - 1s 103us/step - loss: 866.6818 - mse: 866.6819 - mae: 20.6699 - val_loss: 1453.5081 - val_mse: 1453.5079 - val_mae: 26.6304\n",
      "Epoch 94/100\n",
      "6855/6855 [==============================] - 1s 107us/step - loss: 860.3397 - mse: 860.3399 - mae: 20.6027 - val_loss: 1422.4317 - val_mse: 1422.4318 - val_mae: 26.2149\n",
      "Epoch 95/100\n",
      "6855/6855 [==============================] - 1s 108us/step - loss: 855.4691 - mse: 855.4688 - mae: 20.5414 - val_loss: 1445.9752 - val_mse: 1445.9752 - val_mae: 26.4904\n",
      "Epoch 96/100\n",
      "6855/6855 [==============================] - 1s 108us/step - loss: 846.5245 - mse: 846.5248 - mae: 20.4370 - val_loss: 1435.9446 - val_mse: 1435.9445 - val_mae: 26.4755\n",
      "Epoch 97/100\n",
      "6855/6855 [==============================] - 1s 114us/step - loss: 842.2387 - mse: 842.2387 - mae: 20.3719 - val_loss: 1464.7498 - val_mse: 1464.7498 - val_mae: 26.8669\n",
      "Epoch 98/100\n",
      "6855/6855 [==============================] - 1s 117us/step - loss: 840.8955 - mse: 840.8956 - mae: 20.3680 - val_loss: 1430.5306 - val_mse: 1430.5306 - val_mae: 26.2101\n",
      "Epoch 99/100\n",
      "6855/6855 [==============================] - 1s 118us/step - loss: 828.8268 - mse: 828.8266 - mae: 20.2183 - val_loss: 1426.1414 - val_mse: 1426.1416 - val_mae: 26.2765\n",
      "Epoch 100/100\n",
      "6855/6855 [==============================] - 1s 126us/step - loss: 830.7298 - mse: 830.7300 - mae: 20.2383 - val_loss: 1426.1531 - val_mse: 1426.1530 - val_mae: 26.3356\n",
      "38.368930365196654\n",
      "30.52551651321333\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "features = ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "features = []\n",
    "rlist=['PM2.5','PM10','NO','NO2','CO']\n",
    "newlist = rlist + ['Temperature','Relative Humidity','windX','windY','Year','MonthX','MonthY','hourX','hourY','isWeekend']\n",
    "for i in newlist:\n",
    "    for j in range(24):\n",
    "        features.append(i+'_t-'+str(j))\n",
    "predVector = []\n",
    "for j in range(24):\n",
    "    predVector.append('PM2.5_t+'+str(j))\n",
    "X = df[features]\n",
    "y = df[predVector]\n",
    "scaler = StandardScaler()\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "scaler.fit(Xtrain)\n",
    "print(Xtrain.shape)\n",
    "with tf.device('/CPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=360, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(24, activation='linear'))\n",
    "    model.summary()\n",
    "    #Fit\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "    history = model.fit(scaler.transform(Xtrain), ytrain, epochs=100, batch_size=50,  verbose=1, validation_split=0.2)\n",
    "    #Print Accuracy\n",
    "    testPred = model.predict(scaler.transform(Xtest))\n",
    "    trainPred = model.predict(scaler.transform(Xtrain))\n",
    "    print(mean_squared_error(testPred, ytest,squared=False))\n",
    "    print(mean_squared_error(trainPred, ytrain,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mse', 'val_mae', 'loss', 'mse', 'mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for loss\n",
    "plt.plot(np.sqrt(history.history['loss']))\n",
    "plt.plot(np.sqrt(history.history['val_loss']))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('RMSE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
